\chapter{全文总结}
本文主要研究了复杂边界流动的格子Boltzmann模拟在GPU上的高性能并行实现。

我们首先按文献中常见的运用共享内存进行辅助迁移的方法
实现了针对简单流动的LBM算法GPU程序，并用其
模拟了二维顶盖驱动方腔流和三维外力驱动方截面直管道流。
在验证了程序正确性后我们测试了其计算速度。我们发现
在简单流场情况下，利用该方法可以达到相对于CPU程序
两个量级的加速比。

考虑到GPU搭载的共享内存十分有限，在实现多组分LBM模型的时候
共享内存大小容易成为性能瓶颈，我们在接下来实现的程序中并没有
采用前面利用共享内存辅助迁移的方案，
而是探究了其他优化方法，其一为利用位操作结合逻辑运算减少访存量
并优化指令流，其二为利用稀疏存储模式大幅降低模拟多孔介质流动时
的计算量。我们分别基于这两种优化方法编制了相应的GPU程序计算
一种理想多孔介质模型（BCC结构）的绝对渗透率，计算结果与解析解
吻合良好，随后测试了两种优化方法的效果，发现第二种算法具有较大
优势，能大幅减少显存耗用和计算量，尤其是在多孔介质孔隙率较低的情况下。

%目前模拟多孔介质内多组分多相流动的LBM
本文另外一个工作是针对我们所使用的多组分LBM模型计算特点，
提出了该模型在GPU上的高效实现方法，并基于这个方法开发了具有一定通用性的GPU并行计算程序。
在利用该程序其模拟了基本的多相问题，验证了其正确性之后，我们用它模拟了真实多孔介质中的多相渗流。
最后，我们还对其进行了性能测试和分析。

本研究工作还有一些问题值得进一步研究，如目前的计算程序只使用了单GPU计算，
实际进行大规模三维并行LBM模拟时，
单个GPU提供的显存空间有限，必须结合使用多线程技术或OPENMP/MPI并行利用多个GPU并行计算才能满足
存储空间要求。另外我们实现的GPU程序的通用性有待进一步提高，如实现不同如入口边界条件的设置等等。
笔者将在今后的工作中着手解决这些问题。
